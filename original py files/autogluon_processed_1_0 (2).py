# -*- coding: utf-8 -*-
"""AutoGluon-processed_1.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DoUsDxZu3MQoio6p3Lm4-Zl_mPG6syCm
"""

# === AutoGluon (best_quality), CPU-only, 1h, 100 trials, reuse existing splits if available ===
!pip install --quiet autogluon

# === LOAD preprocessed splits exactly as used in your other file ===
import pandas as pd
from google.colab import drive

drive.mount('/content/drive', force_remount=True)
path = "/content/drive/MyDrive/UCL_Dissertation"

# Load
df_tr = pd.read_csv(f"{path}/train_preproc.csv")
df_va = pd.read_csv(f"{path}/val_preproc.csv")
df_te = pd.read_csv(f"{path}/test_preproc.csv")

# Target detection (keeps your original logic)
CANDIDATE_TARGETS = ["Actual_Length", "actual_length", "target", "Target", "y", "duration", "Duration"]
tcol = next((c for c in CANDIDATE_TARGETS if c in df_tr.columns), None)

if tcol is None:
    diff_tr = list(set(df_tr.columns) - set(df_te.columns))
    diff_va = list(set(df_va.columns) - set(df_te.columns))
    if len(diff_tr) == 1 and len(diff_va) == 1 and diff_tr[0] == diff_va[0]:
        tcol = diff_tr[0]

assert tcol is not None, "Couldn't infer target column; please ensure target exists in train/val."

# Split into X/y
y_tr = df_tr[tcol].copy()
y_va = df_va[tcol].copy()
y_te = df_te[tcol].copy() if tcol in df_te.columns else None

X_tr = df_tr.drop(columns=[tcol])
X_va = df_va.drop(columns=[tcol])
X_te = df_te.drop(columns=[tcol]) if tcol in df_te.columns else df_te.copy()

# Align features (intersection)
common_cols = sorted(set(X_tr.columns) & set(X_va.columns) & set(X_te.columns))
X_tr, X_va, X_te = X_tr[common_cols], X_va[common_cols], X_te[common_cols]

# Report
print("=== DATA LOADED FROM preproc CSVs ===")
print(f"Target: {tcol}")
print(f"Aligned feature columns: {len(common_cols)}")
print("Train X:", X_tr.shape, "| y:", y_tr.shape)
print("Val   X:", X_va.shape, "| y:", y_va.shape)
print("Test  X:", X_te.shape, "| y:", None if y_te is None else y_te.shape)
print("\nFirst 10 feature cols:", common_cols[:10])

# === AutoGluon: same split as other models; CPU-only; best_quality; 1h; 100 trials ===
!pip install --quiet autogluon

import os, pandas as pd
from autogluon.tabular import TabularPredictor

# Reuse variables from the loader cell:
assert all(v in globals() for v in ["X_tr","y_tr","X_va","y_va","X_te","tcol"]), "Run the loader cell first."

drive_path = "/content/drive"
proj_dir   = f"{drive_path}/MyDrive/UCL_Dissertation"
ag_path    = f"{proj_dir}/autogluon_bestq_cpu_1h_100trials"

# Assemble frames for AG
train_data = X_tr.copy(); train_data[tcol] = y_tr.values
val_data   = X_va.copy(); val_data[tcol]   = y_va.values
test_data  = X_te.copy()  # no target in test by design

predictor = TabularPredictor(
    label=tcol,
    path=ag_path,
    problem_type="regression",
    eval_metric="mae",
).fit(
    train_data=train_data,
    tuning_data=val_data,      # your fixed validation split
    presets="best_quality",
    time_limit=3600,           # 1 hour
    num_gpus=0,                # CPU-only
    use_bag_holdout=True,      # <-- key fix for best_quality + external val
    dynamic_stacking=False,    # optional: avoid DyStack warm-up
    num_stack_levels=1         # optional: keep default stack depth
)


# Quick leaderboard on the validation set
lb_val = predictor.leaderboard(val_data, silent=True)
print(lb_val.head(10))

# Predict on test and save
pred_test = predictor.predict(test_data)
out_csv = f"{ag_path}/test_predictions.csv"
pd.DataFrame({"prediction": pred_test}).to_csv(out_csv, index=False)
print("Saved test predictions to:", out_csv)

# Optional: evaluate if your test has targets
if 'y_te' in globals() and y_te is not None:
    perf_te = predictor.evaluate(pd.concat([test_data.copy(), y_te.rename(tcol)], axis=1))
    print("Held-out test performance:", perf_te)

# === Metrics from saved predictions (append-safe block) ===
# Computes AG metrics (sign-corrected), sklearn MAE/RMSE/R2, and ±window accuracies (5/10/15%)
# Targets the 100-trials run: /content/drive/MyDrive/UCL_Dissertation/autogluon_bestq_cpu_1h_100trials

import os
import numpy as np
import pandas as pd
from autogluon.tabular import TabularPredictor

# ---- Correct paths for *100-trials* run ----
model_save_path = "/content/drive/MyDrive/UCL_Dissertation/autogluon_bestq_cpu_1h_100trials"
test_preds_path  = f"{model_save_path}/test_predictions.csv"
train_preds_path = f"{model_save_path}/train_predictions.csv"  # optional; only if you saved it

def _find_cols(df):
    """Auto-detect y_true and y_pred columns in the predictions CSV."""
    y_cols = [c for c in df.columns if c.lower() in ["actual_length", "label"]]
    p_cols = [c for c in df.columns if c.lower() in ["prediction", "pred"]]
    if not y_cols or not p_cols:
        raise ValueError(f"Could not find label/pred columns in {df.columns.tolist()}")
    return y_cols[0], p_cols[0]

def _load_preds(path):
    df = pd.read_csv(path)
    y_col, p_col = _find_cols(df)
    y_true = pd.Series(df[y_col], name=y_col)
    y_pred = pd.Series(df[p_col], name=p_col)
    mask = ~(y_true.isna() | y_pred.isna())
    return y_true[mask].astype(float), y_pred[mask].astype(float)

def _ag_metrics(predictor, y_true, y_pred):
    ag = predictor.evaluate_predictions(y_true=y_true, y_pred=y_pred, auxiliary_metrics=True)
    return {k: (-v if any(tok in k for tok in ["error", "loss"]) else v) for k, v in ag.items()}

def _sklearn_metrics(y_true, y_pred):
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = float(np.sqrt(mse))  # robust to older sklearn (no squared=False)
    r2 = r2_score(y_true, y_pred)
    return {"MAE": mae, "RMSE": rmse, "R2": r2}

def _window_accuracy(y_true, y_pred, pct=0.10, base="actual"):
    diff = (y_pred - y_true).abs()
    tol = pct * (y_true.abs() if base == "actual" else y_pred.abs())
    return diff <= tol

def _summarize_windows(y_true, y_pred, percentages=(0.05, 0.10, 0.15)):
    rows = []
    for p in percentages:
        in_a = _window_accuracy(y_true, y_pred, pct=p, base="actual")
        in_p = _window_accuracy(y_true, y_pred, pct=p, base="pred")
        rows.append({
            "Window": f"±{int(p*100)}%",
            "Actual-based Acc (%)": round(float(in_a.mean() * 100), 2),
            "Pred-based Acc (%)":   round(float(in_p.mean() * 100), 2),
            "Within (actual)": int(in_a.sum()),
            "Outside (actual)": int((~in_a).sum()),
            "Within (pred)":   int(in_p.sum()),
            "Outside (pred)":  int((~in_p).sum()),
        })
    return pd.DataFrame(rows)

def _print_block(title, agm, skm, win_df):
    print(f"\n=== {title} ===")
    print("\nAutoGluon metrics (sign-corrected):")
    for k, v in agm.items():
        print(f"{k:25s}: {v:.4f}")
    print("\nSklearn metrics:")
    for k, v in skm.items():
        print(f"{k:25s}: {v:.4f}")
    print("\nWindow metrics:")
    print(win_df.to_string(index=False))

# ---- Load predictor once ----
predictor = TabularPredictor.load(model_save_path)

# ---- TEST ----
if os.path.exists(test_preds_path):
    print(f"Loading TEST predictions: {test_preds_path}")
    y_true_te, y_pred_te = _load_preds(test_preds_path)
    ag_te = _ag_metrics(predictor, y_true_te, y_pred_te)
    sk_te = _sklearn_metrics(y_true_te, y_pred_te)
    win_te = _summarize_windows(y_true_te, y_pred_te, percentages=(0.05, 0.10, 0.15))
    _print_block("TEST", ag_te, sk_te, win_te)
else:
    print(f"[WARN] test_predictions.csv not found at: {test_preds_path}")

# ---- TRAIN (optional) ----
if os.path.exists(train_preds_path):
    print(f"\nLoading TRAIN predictions: {train_preds_path}")
    y_true_tr, y_pred_tr = _load_preds(train_preds_path)
    ag_tr = _ag_metrics(predictor, y_true_tr, y_pred_tr)
    sk_tr = _sklearn_metrics(y_true_tr, y_pred_tr)
    win_tr = _summarize_windows(y_true_tr, y_pred_tr, percentages=(0.05, 0.10, 0.15))
    _print_block("TRAIN", ag_tr, sk_tr, win_tr)
else:
    print("\nNo train_predictions.csv found — reporting TEST only.")

# === Recover labels by scanning disk, then compute metrics on saved predictions ===
import os
import math
import numpy as np
import pandas as pd
from autogluon.tabular import TabularPredictor

PRED_PATH = "/content/drive/MyDrive/UCL_Dissertation/autogluon_bestq_cpu_1h_100trials/test_predictions.csv"
ROOT_DIR  = "/content/drive/MyDrive/UCL_Dissertation"
LABEL_COL = "Actual_Length"

# 1) Load predictions
df_pred = pd.read_csv(PRED_PATH)
if "prediction" not in df_pred.columns:
    raise ValueError(f"[FATAL] 'prediction' column missing in {PRED_PATH}. Columns={df_pred.columns.tolist()}")
y_pred = df_pred["prediction"].astype(float).reset_index(drop=True)
target_len = len(y_pred)
print(f"[INFO] Loaded predictions: shape={df_pred.shape} (target_len={target_len})")

# 2) Scan disk for a matching labels file
CAND_EXT = (".csv", ".parquet", ".feather")
KEYWORDS = ["test", "split", "processedsplit"]  # preferred indicators in filenames

def _score_path(path):
    name = os.path.basename(path).lower()
    score = 0
    for k in KEYWORDS:
        if k in name:
            score += 2
    # de-prioritize obviously unrelated
    if "train" in name:
        score -= 1
    if "prediction" in name:
        score -= 1
    return score

def _try_read(path):
    try:
        if path.endswith(".csv"):
            return pd.read_csv(path, low_memory=False)
        elif path.endswith(".parquet"):
            return pd.read_parquet(path)
        elif path.endswith(".feather"):
            return pd.read_feather(path)
    except Exception as e:
        print(f"[SKIP] Failed to read {path}: {e}")
    return None

candidates = []
for root, _, files in os.walk(ROOT_DIR):
    for fn in files:
        if fn.lower().endswith(CAND_EXT):
            full = os.path.join(root, fn)
            # quick stat to avoid heavy reads (optional)
            # Try read small; we will fully read, but handle exceptions gracefully
            df = _try_read(full)
            if df is None:
                continue
            if LABEL_COL in df.columns and len(df) == target_len:
                # sanity: label column should be numeric-ish
                try:
                    s = pd.to_numeric(df[LABEL_COL], errors="coerce")
                    if s.isna().mean() < 0.10:  # allow up to 10% NaNs
                        candidates.append((full, _score_path(full)))
                except Exception:
                    pass

if not candidates:
    raise RuntimeError(
        f"[FATAL] Could not find any file under {ROOT_DIR} with column '{LABEL_COL}' "
        f"and {target_len} rows to match predictions."
    )

# pick best by score, then shortest path as tie-breaker
candidates.sort(key=lambda x: (-x[1], len(x[0])))
label_path, path_score = candidates[0]
print(f"[INFO] Using label file: {label_path} (score={path_score})")

df_labels = _try_read(label_path)
y_true = pd.to_numeric(df_labels[LABEL_COL], errors="coerce").reset_index(drop=True)

# 3) Align lengths (defensive)
n = min(len(y_true), len(y_pred))
if len(y_true) != len(y_pred):
    print(f"[WARN] Length mismatch: labels={len(y_true)}, preds={len(y_pred)} → truncating to {n}")
y_true = y_true.iloc[:n]
y_pred = y_pred.iloc[:n]

# 4) Compute metrics
predictor = TabularPredictor.load("/content/drive/MyDrive/UCL_Dissertation/autogluon_bestq_cpu_1h_100trials")

# AutoGluon evaluate (returns negative for error
# === Finalize metrics + save artifacts (runs after the scan) ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from autogluon.tabular import TabularPredictor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import os

MODEL_DIR = "/content/drive/MyDrive/UCL_Dissertation/autogluon_bestq_cpu_1h_100trials"
os.makedirs(MODEL_DIR, exist_ok=True)

# y_true and y_pred should already exist from the scan block.
# If they don't for some reason, uncomment the two lines below to reload:
# y_pred = pd.read_csv(f"{MODEL_DIR}/test_predictions.csv")["prediction"].astype(float).reset_index(drop=True)
# y_true = pd.read_csv("/content/drive/MyDrive/UCL_Dissertation/y_test.csv")["Actual_Length"].astype(float).reset_index(drop=True)

n = min(len(y_true), len(y_pred))
y_true = y_true.iloc[:n].astype(float)
y_pred = y_pred.iloc[:n].astype(float)

predictor = TabularPredictor.load(MODEL_DIR)

# AutoGluon metrics (flip sign for error metrics)
ag_raw = predictor.evaluate_predictions(y_true=y_true, y_pred=y_pred, auxiliary_metrics=True)
ag = {k: (-v if any(tok in k for tok in ["error", "loss"]) else v) for k, v in ag_raw.items()}

# Sklearn metrics
mae  = mean_absolute_error(y_true, y_pred)
mse  = mean_squared_error(y_true, y_pred)
rmse = float(np.sqrt(mse))
r2   = r2_score(y_true, y_pred)

# Window metrics
def _win_mask(y_t, y_p, pct=0.10, base="actual"):
    diff = (y_p - y_t).abs()
    tol  = pct * (y_t.abs() if base == "actual" else y_p.abs())
    return diff <= tol

def _summ_windows(y_t, y_p, pcts=(0.05, 0.10, 0.15)):
    rows = []
    for p in pcts:
        m_a = _win_mask(y_t, y_p, pct=p, base="actual")
        m_p = _win_mask(y_t, y_p, pct=p, base="pred")
        rows.append({
            "Window": f"±{int(p*100)}%",
            "Actual-based Acc (%)": round(float(m_a.mean()*100), 2),
            "Pred-based Acc (%)":   round(float(m_p.mean()*100), 2),
            "Within (actual)": int(m_a.sum()),
            "Outside (actual)": int((~m_a).sum()),
            "Within (pred)":   int(m_p.sum()),
            "Outside (pred)":  int((~m_p).sum()),
        })
    return pd.DataFrame(rows)

win_df = _summ_windows(y_true, y_pred, pcts=(0.05, 0.10, 0.15))

# Print
print("\n=== TEST — autogluon_bestq_cpu_1h_100trials ===")
print("\nAutoGluon metrics (sign-corrected):")
for k, v in ag.items():
    print(f"{k:25s}: {v:.4f}")

print("\nSklearn metrics:")
print(f"{'MAE':25s}: {mae:.4f}")
print(f"{'RMSE':25s}: {rmse:.4f}")
print(f"{'R2':25s}: {r2:.4f}")

print("\nWindow metrics:")
print(win_df.to_string(index=False))

# Save artifacts
pd.DataFrame([ag]).to_csv(f"{MODEL_DIR}/metrics_ag.csv", index=False)
pd.DataFrame([{"MAE": mae, "RMSE": rmse, "R2": r2}]).to_csv(f"{MODEL_DIR}/metrics_sklearn.csv", index=False)
win_df.to_csv(f"{MODEL_DIR}/window_metrics.csv", index=False)

# Residuals plot (ŷ vs y with diagonal)
plt.figure(figsize=(6,6))
plt.scatter(y_true, y_pred, s=4, alpha=0.4)
mn, mx = float(min(y_true.min(), y_pred.min())), float(max(y_true.max(), y_pred.max()))
plt.plot([mn, mx], [mn, mx], linewidth=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Predicted vs Actual (TEST)")
plt.tight_layout()
plot_path = f"{MODEL_DIR}/residuals_scatter.png"
plt.savefig(plot_path, dpi=150)
print(f"\nSaved: metrics_ag.csv, metrics_sklearn.csv, window_metrics.csv, residuals_scatter.png → {MODEL_DIR}")

